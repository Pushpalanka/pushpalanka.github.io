<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Beyond Race Detectors: First-hand Experience Debugging a Multi-threaded Stale Data Issue | Pushpalanka</title><meta name=keywords content="go,concurrency,debugging,multi-threading,opa,skipper,zalando"><meta name=description content="Sharing first hand experience with OPA's plugin manager, demonstrating a snapshot-based, inconsistent notification problem"><meta name=author content="Pushpalanka"><link rel=canonical href=https://pushpalanka.com/posts/beyond-race-detectors><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://pushpalanka.com/push-favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://pushpalanka.com/push-favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://pushpalanka.com/push-favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://pushpalanka.com/push-favicon/apple-touch-icon.png><link rel=mask-icon href=https://pushpalanka.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://pushpalanka.com/posts/beyond-race-detectors/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta name=apple-mobile-web-app-title content="Pushpalanka"><link rel=manifest href=/push-favicon/site.webmanifest><link rel=icon type=image/svg+xml href=/push-favicon/favicon.svg><meta property="og:url" content="https://pushpalanka.com/posts/beyond-race-detectors/"><meta property="og:site_name" content="Pushpalanka"><meta property="og:title" content="Beyond Race Detectors: First-hand Experience Debugging a Multi-threaded Stale Data Issue"><meta property="og:description" content="Sharing first hand experience with OPA's plugin manager, demonstrating a snapshot-based, inconsistent notification problem"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-11-11T00:00:00+00:00"><meta property="article:modified_time" content="2025-11-11T00:00:00+00:00"><meta property="article:tag" content="Go"><meta property="article:tag" content="Concurrency"><meta property="article:tag" content="Debugging"><meta property="article:tag" content="Multi-Threading"><meta property="article:tag" content="Opa"><meta property="article:tag" content="Skipper"><meta property="og:image" content="https://pushpalanka.com/images/beyond-race-detectors/detective.webp"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://pushpalanka.com/images/beyond-race-detectors/detective.webp"><meta name=twitter:title content="Beyond Race Detectors: First-hand Experience Debugging a Multi-threaded Stale Data Issue"><meta name=twitter:description content="Sharing first hand experience with OPA's plugin manager, demonstrating a snapshot-based, inconsistent notification problem"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://pushpalanka.com/posts/"},{"@type":"ListItem","position":2,"name":"Beyond Race Detectors: First-hand Experience Debugging a Multi-threaded Stale Data Issue","item":"https://pushpalanka.com/posts/beyond-race-detectors/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Beyond Race Detectors: First-hand Experience Debugging a Multi-threaded Stale Data Issue","name":"Beyond Race Detectors: First-hand Experience Debugging a Multi-threaded Stale Data Issue","description":"Sharing first hand experience with OPA's plugin manager, demonstrating a snapshot-based, inconsistent notification problem","keywords":["go","concurrency","debugging","multi-threading","opa","skipper","zalando"],"articleBody":"During a new feature rollout of Skipper (An opensource ingress controller from Zalando), we hit a puzzling issue: \u003c5% of requests to a specific route failed consistently in one pod, while the same configuration worked perfectly everywhere else. The culprit? A timing-dependent bug in how OPA‚Äôs plugin manager handles state notifications - one that Go‚Äôs race detector won‚Äôt catch.\n(If a more visual representation is appealing to you, refer the slide deck shared at https://pushpalanka.com/posts/stale-snapshot-case. It was prepared as an industry example for concurrency and operating system students.)\n1. Overview This post explores a snapshot consistency problem in notification systems. It only appeared when starting 50+ OPA instances in parallel, revealing how resource contention can expose narrow timing windows in seemingly safe code. In this post, I‚Äôll share the journey of detecting, reproducing, isolating, and fixing a multi-threading issue that was both difficult to reproduce and even harder to pinpoint.\nThe issue I‚Äôll reference is OPA issue #8009, which surfaced when parallel plugin startups were occurring in Zalando Skipper. This integration is explained in details in this Zalando blogpost.\nWhile this post builds on that specific case, the focus is on the general learnings and practical lessons that apply to debugging complex multi-threaded behavior in real-world systems.\n2. Scenario We released an optimization to the OPA filter creation mechanism in Skipper, that serves as the Ingress controller in our platform. The goal was to achieve faster startup times during large-scale deployments.\nTo do this, we modified the system to start all required OPA instances in parallel, allowing Skipper to become operational more quickly. Any additional OPA instances needed later, would be initialized on-demand in the background, one at a time, as required by the traffic route definitions.\nHere I share the problem-contributing code segments. If you spot the issue at a glance, congratulations!, you‚Äôll save yourself hours debugging similar multi-threading issues.\nNotifier (from OPA plugins) When a plugin‚Äôs status updates, OPA creates a snapshot of all plugin states and notifies listeners,\n// UpdatePluginStatus updates a named plugins status. Any registered // listeners will be called with a copy of the new state of all // plugins. func (m *Manager) UpdatePluginStatus(pluginName string, status *Status) { var toNotify map[string]StatusListener var statuses map[string]*Status func() { m.mtx.Lock() defer m.mtx.Unlock() m.pluginStatus[pluginName] = status toNotify = make(map[string]StatusListener, len(m.pluginStatusListeners)) maps.Copy(toNotify, m.pluginStatusListeners) statuses = m.copyPluginStatus() }() // üî¥ Lock released here - listeners called concurrently for _, l := range toNotify { l(statuses) } } Listener (from Skipper) In each OPA instance running in Skipper, it listens to plugin status changes. At the start up, all OPA instances and their plugins go through state changes when getting active.\nmanager.RegisterPluginStatusListener(\"instance-health-check\", func(status map[string]*plugins.Status) { opa.healthy.Store(allPluginsReady(status, bundle.Name, discovery.Name)) opa.Logger().Info(\"OPA instance health updated: healthy=%t status=%+v\", opa.healthy.Load(), status) }) Now I will share the story of its detection, the struggle and solving.\n3. Issue Detection During staging tests, one of our stakeholder teams reported a consistent error rate of less than 5% on specific requests. The errors were limited to a single route protected by a particular OPA policy and, intriguingly, only in one specific pod.\nThe same OPA policy worked perfectly fine in all other pods, and no other OPA policies showed any issues. Even more puzzling: there were no explicit error logs despite thorough error logging, except for a log indicating that the affected OPA instance became healthy for a fraction of a second, and then immediately unhealthy again and never recovers.\n4. Reproducing We went through the relevant code again and again, critically assessing what could have gone wrong, reviewed the end to end scenarios tests to see if there was anything we could cover more which didn‚Äôt give any clue. Once these basic verifications are done, we could rule out few things.\nIt can‚Äôt be anything related to OPA policy issues - because the policy works in every other pod OPA bundle downloading issues - Logging helped ruling this out. If a download issue or a malformed bundle was present, it does log an error Beyond this, only path we saw was reproducing the issue so we can have a closer look. I also tried different analyse paths with AI coding assistants(Claude Sonnet 4.5 and GPT 5), providing both Skipper and relevant OPA code, which didn‚Äôt lead to anything solid, but lot of vague possibilities.\nReplicate everything as close as possible to the issue occurred environment I used the same OPA bundles as our stakeholders and created a local setup. Made the configurations exact by splitting the data and policy bundles and including the discovery bundles in the configurations. Configured status and decision log reporting to a local server where I can control them to simulate being slow, totally unavailable and recovering. Tried out variety of timing scenarios involving these and bundle server availabilities and slowness. Tools to analyse logs Knowing whether the issue was reproduced or not was also a challenge. This is where AI could effectively help by providing the commands to isolate log patterns. In the issue occurred setup, there were close to 32 OPA instances getting created in parallel.\nMeanwhile the stakeholder agreed to try it once more to gather anything that would help reproducing. This uncovered few more details. Even-though it didn‚Äôt get reproduced in my local setup it was reproducing again in the stakeholder‚Äôs setup, now failing for two OPA instances in one particular pod.\nThis confirmed two things,\nFailure is not specific to a particular OPA policy, but possibly can happen for any Something specific to this stakeholder‚Äôs setup is making it quite easy for the issue to happen With this newly revealed information, I kept on increasing the number of bundles in my local setup. I was going beyond what our stakeholder‚Äôs had and as I go beyond 50 OPA instances, the mysterious issue start to happen consistently. I had the nice command I got from Co-pilot, confirmed it will isolate me the OPA instances that faced the failure and started analyzing the logs.\n5. Debugging This is where things got more interesting.\nWith increased logging, I could finally see more internal activity, but still no actual errors. Among the OPA plugins, I noticed that the bundle plugin was flipping from the OK state back to NOT_READY, which in turn triggered the brief healthy ‚Üí unhealthy transition in OPA‚Äôs overall health status.\nSince I never knew which exact OPA instance would show this behavior ahead of time, logging became my friend, traditional step debugging in the IDE wasn‚Äôt practical. So I relied heavily on structured logs, they became my eyes inside the concurrency maze.\nThe mystery deepened further:\nthere was no code path that actually transitioned the bundle plugin from OK to NOT_READY between those health flips.\nThat raised a fundamental question:\nHow could our health listener observe the bundle plugin switching back to NOT_READY when no execution ever performed that state change?\nThe Breakthrough Two Go routines racing with each other, one with stale data\nI added one critical log line:\nfor _, l := range toNotify { m.logger.Info(\"UpdatePluginStatus: plugin status listener %+v status manager %+v\", statuses, m.pluginStatus) l(statuses) } Which printed,\n\"UpdatePluginStatus: plugin status listener map[bundle:{**NOT_READY** \\\"\\\"} decision_logs:{OK \\\"\\\"} discovery:{OK \\\"\\\"} envoy_ext_authz_grpc:{OK \\\"\\\"} status:{OK \\\"\\\"}] status manager map[bundle:{**OK** \\\"\\\"} decision_logs:{OK \\\"\\\"} discovery:{OK \\\"\\\"} envoy_ext_authz_grpc:{OK \\\"\\\"} status:{OK \\\"\\\"}]\" bundle-name=bundles/discovery6.tar.gz The race:\nThe Timeline: Two Routines, One Stale Snapshot Time Routine A Routine B T1 UpdatePluginStatus(\"bundle\", NOT_READY) T2 Lock ‚Üí Update ‚Üí Create snapshotS1 = {NOT_READY} ‚Üí Unlock T3 ‚ö†Ô∏è Preempted before calling listeners T4 UpdatePluginStatus(\"bundle\", OK) T5 Lock ‚Üí Update ‚Üí Create snapshotS2 = {OK} ‚Üí Unlock T6 Call listeners with snapshot S2 ‚úÖ T7 Resumes ‚Äî Calls listeners with old snapshot S1 ‚ùå Result:\nRoutine A‚Äôs delayed listener call overwrote Routine B‚Äôs newer state, making the system appear to revert to NOT_READY ‚Äî even though it was already healthy.\nTimeline with routines getting pre-empted\n6. Fixing Once isolated we had a one-line fix that could be done in Skipper side. Instead of trusting the snapshot passed to the listener, directly query the manager‚Äôs current state.\nmanager.RegisterPluginStatusListener(\"instance-health-check\", func(_ map[string]*plugins.Status) { // Get fresh status to workaround OPA issue https://github.com/open-policy-agent/opa/issues/8009 status := opa.manager.PluginStatus() // \u003c- fix, overrrides the pass in status map to the listener opa.healthy.Store(allPluginsReady(status, bundle.Name, discovery.Name)) opa.Logger().Info(\"OPA instance health updated: healthy=%t status=%+v\", opa.healthy.Load(), status) }) Why this works: We bypass the snapshot race by always reading the real-time state from the source of truth (the manager), rather than relying on potentially stale snapshots delivered via notifications.\n7. Learnings 1. AI as a Productivity Tool, Not a Debugger AI models aren‚Äôt mature enough yet to analyze complex multi-threading issues, but they excel at accelerating the process by generating log parsing commands, documenting findings, and explaining unfamiliar codebases. The actual debugging still requires human intuition.\n2. Strategic Logging Over Verbose Logging Good logging saves time, but there‚Äôs a balance. Log state transitions with context, not every operation. Key questions will be, ‚ÄúWill this log help confirm or rule out something critical? How often will it fire?‚Äù Debug logging everywhere reduces readability and buries the signal in noise.\n3. Every Bug is Reproducible (With Enough Persistence) This seemed impossible to reproduce initially. By systematically varying parameters, replicating the environment, and investing consistent effort over days, I could find conditions to reliably reproduce it. Reproducibility isn‚Äôt binary, it‚Äôs about finding the right conditions. When stakes are high, persistence pays off.\n4. Race Detectors Catch Data Races Go‚Äôs race detector excels at finding unsynchronized memory access but didn‚Äôt detect event ordering races like this, logical races in state machines, or snapshot consistency problems. Multi-threading issues are often about event ordering and state consistency, not just data races. Manual reasoning is essential.\n5. Logs Beat Debuggers for Concurrent Bugs When issues reproduce randomly and concurrency is suspected, logging is more effective than IDE debugging. You can‚Äôt step through race conditions. To compensate for losing interactive stack traces, print stack traces directly in logs at critical state transitions for debugging purposes.\n6. Question Your Assumptions Explicitly Write down what you believe to be true and verify each assumption:\n‚ÄúNOT_READY‚Äù means broken\" ‚Üí Actually: Real state was OK, snapshot was stale ‚ÄúAll state changes notify‚Äù ‚Üí Actually: Some state changes are protected by sync.Once so not all updates are notified Half the battle is realizing what you thought to be true isn‚Äôt.\nConclusion This bug broadened my horizons, that multi-threading issues aren‚Äôt always about locks and data races, they are about information propagation and timing assumptions as well.\nFull technical details Skipper Issue #3687 Skipper PR #3692 Workaround Skipper PR #3562 (Preloading feature that exposed the bug) OPA Integration in Skipper OPA issue report #8009 Cheers! üéØ ‚ú®\n","wordCount":"1771","inLanguage":"en","image":"https://pushpalanka.com/images/beyond-race-detectors/detective.webp","datePublished":"2025-11-11T00:00:00Z","dateModified":"2025-11-11T00:00:00Z","author":{"@type":"Person","name":"Pushpalanka"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://pushpalanka.com/posts/beyond-race-detectors/"},"publisher":{"@type":"Organization","name":"Pushpalanka","logo":{"@type":"ImageObject","url":"https://pushpalanka.com/push-favicon/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://pushpalanka.com/ accesskey=h title="Pushpalanka (Alt + H)">Pushpalanka</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://pushpalanka.com/posts/ title=Articles><span>Articles</span></a></li><li><a href=https://pushpalanka.com/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://pushpalanka.com/>Home</a>&nbsp;¬ª&nbsp;<a href=https://pushpalanka.com/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Beyond Race Detectors: First-hand Experience Debugging a Multi-threaded Stale Data Issue</h1><div class=post-description>Sharing first hand experience with OPA's plugin manager, demonstrating a snapshot-based, inconsistent notification problem</div><div class=post-meta><span title='2025-11-11 00:00:00 +0000 UTC'>November 11, 2025</span>&nbsp;¬∑&nbsp;<span>9 min</span>&nbsp;¬∑&nbsp;<span>Pushpalanka</span></div></header><figure class=entry-cover><img loading=eager src=https://pushpalanka.com/images/beyond-race-detectors/detective.webp alt="Multi-threading debugging illustration"></figure><div class=post-content><p>During a new feature rollout of Skipper (An opensource ingress controller from Zalando), we hit a puzzling issue: &lt;5% of requests to a specific route failed consistently in one pod, while the same configuration worked perfectly everywhere else. The culprit? A timing-dependent bug in how OPA&rsquo;s plugin manager handles state notifications - one that Go&rsquo;s race detector won&rsquo;t catch.</p><p><em>(If a more visual representation is appealing to you, refer the slide deck shared at <a href=https://pushpalanka.com/posts/stale-snapshot-case>https://pushpalanka.com/posts/stale-snapshot-case</a>. It was prepared as an industry example for concurrency and operating system students.)</em></p><h2 id=1-overview>1. Overview<a hidden class=anchor aria-hidden=true href=#1-overview>#</a></h2><p>This post explores a snapshot consistency problem in notification systems. It only appeared when starting 50+ OPA instances in parallel, revealing how resource contention can expose narrow timing windows in seemingly safe code. In this post, I&rsquo;ll share the journey of detecting, reproducing, isolating, and fixing a multi-threading issue that was both difficult to reproduce and even harder to pinpoint.</p><p>The issue I&rsquo;ll reference is <a href=https://github.com/open-policy-agent/opa/issues/8009>OPA issue #8009</a>, which surfaced when parallel plugin startups were occurring in Zalando Skipper. This integration is explained in details in <a href=https://opensource.zalando.com/skipper/>this Zalando blogpost</a>.</p><p>While this post builds on that specific case, the focus is on the general learnings and practical lessons that apply to debugging complex multi-threaded behavior in real-world systems.</p><h2 id=2-scenario>2. Scenario<a hidden class=anchor aria-hidden=true href=#2-scenario>#</a></h2><p>We released an optimization to the OPA filter creation mechanism in Skipper, that serves as the Ingress controller in our platform. The goal was to achieve faster startup times during large-scale deployments.</p><p>To do this, we modified the system to start all required OPA instances in parallel, allowing Skipper to become operational more quickly. Any additional OPA instances needed later, would be initialized on-demand in the background, one at a time, as required by the traffic route definitions.</p><p>Here I share the problem-contributing code segments. If you spot the issue at a glance, congratulations!, you&rsquo;ll save yourself hours debugging similar multi-threading issues.</p><h3 id=notifier-from-opa-plugins>Notifier (from OPA plugins)<a hidden class=anchor aria-hidden=true href=#notifier-from-opa-plugins>#</a></h3><p>When a plugin&rsquo;s status updates, OPA creates a snapshot of all plugin states and notifies listeners,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#75715e>// UpdatePluginStatus updates a named plugins status. Any registered</span>
</span></span><span style=display:flex><span><span style=color:#75715e>// listeners will be called with a copy of the new state of all</span>
</span></span><span style=display:flex><span><span style=color:#75715e>// plugins.</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>func</span> (<span style=color:#a6e22e>m</span> <span style=color:#f92672>*</span><span style=color:#a6e22e>Manager</span>) <span style=color:#a6e22e>UpdatePluginStatus</span>(<span style=color:#a6e22e>pluginName</span> <span style=color:#66d9ef>string</span>, <span style=color:#a6e22e>status</span> <span style=color:#f92672>*</span><span style=color:#a6e22e>Status</span>) {
</span></span><span style=display:flex><span> <span style=color:#66d9ef>var</span> <span style=color:#a6e22e>toNotify</span> <span style=color:#66d9ef>map</span>[<span style=color:#66d9ef>string</span>]<span style=color:#a6e22e>StatusListener</span>
</span></span><span style=display:flex><span> <span style=color:#66d9ef>var</span> <span style=color:#a6e22e>statuses</span> <span style=color:#66d9ef>map</span>[<span style=color:#66d9ef>string</span>]<span style=color:#f92672>*</span><span style=color:#a6e22e>Status</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span> <span style=color:#66d9ef>func</span>() {
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>m</span>.<span style=color:#a6e22e>mtx</span>.<span style=color:#a6e22e>Lock</span>()
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>defer</span> <span style=color:#a6e22e>m</span>.<span style=color:#a6e22e>mtx</span>.<span style=color:#a6e22e>Unlock</span>()
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>m</span>.<span style=color:#a6e22e>pluginStatus</span>[<span style=color:#a6e22e>pluginName</span>] = <span style=color:#a6e22e>status</span>
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>toNotify</span> = make(<span style=color:#66d9ef>map</span>[<span style=color:#66d9ef>string</span>]<span style=color:#a6e22e>StatusListener</span>, len(<span style=color:#a6e22e>m</span>.<span style=color:#a6e22e>pluginStatusListeners</span>))
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>maps</span>.<span style=color:#a6e22e>Copy</span>(<span style=color:#a6e22e>toNotify</span>, <span style=color:#a6e22e>m</span>.<span style=color:#a6e22e>pluginStatusListeners</span>)
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>statuses</span> = <span style=color:#a6e22e>m</span>.<span style=color:#a6e22e>copyPluginStatus</span>()
</span></span><span style=display:flex><span> }()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// üî¥ Lock released here - listeners called concurrently</span>
</span></span><span style=display:flex><span> <span style=color:#66d9ef>for</span> <span style=color:#a6e22e>_</span>, <span style=color:#a6e22e>l</span> <span style=color:#f92672>:=</span> <span style=color:#66d9ef>range</span> <span style=color:#a6e22e>toNotify</span> {
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>l</span>(<span style=color:#a6e22e>statuses</span>)
</span></span><span style=display:flex><span> }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=listener-from-skipper>Listener (from Skipper)<a hidden class=anchor aria-hidden=true href=#listener-from-skipper>#</a></h3><p>In each OPA instance running in Skipper, it listens to plugin status changes. At the start up, all OPA instances and their plugins go through state changes when getting active.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span> <span style=color:#a6e22e>manager</span>.<span style=color:#a6e22e>RegisterPluginStatusListener</span>(<span style=color:#e6db74>&#34;instance-health-check&#34;</span>, <span style=color:#66d9ef>func</span>(<span style=color:#a6e22e>status</span> <span style=color:#66d9ef>map</span>[<span style=color:#66d9ef>string</span>]<span style=color:#f92672>*</span><span style=color:#a6e22e>plugins</span>.<span style=color:#a6e22e>Status</span>) {
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>opa</span>.<span style=color:#a6e22e>healthy</span>.<span style=color:#a6e22e>Store</span>(<span style=color:#a6e22e>allPluginsReady</span>(<span style=color:#a6e22e>status</span>, <span style=color:#a6e22e>bundle</span>.<span style=color:#a6e22e>Name</span>, <span style=color:#a6e22e>discovery</span>.<span style=color:#a6e22e>Name</span>))
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>opa</span>.<span style=color:#a6e22e>Logger</span>().<span style=color:#a6e22e>Info</span>(<span style=color:#e6db74>&#34;OPA instance health updated: healthy=%t status=%+v&#34;</span>, <span style=color:#a6e22e>opa</span>.<span style=color:#a6e22e>healthy</span>.<span style=color:#a6e22e>Load</span>(), <span style=color:#a6e22e>status</span>)
</span></span><span style=display:flex><span> })
</span></span></code></pre></div><p>Now I will share the story of its detection, the struggle and solving.</p><h2 id=3-issue-detection>3. Issue Detection<a hidden class=anchor aria-hidden=true href=#3-issue-detection>#</a></h2><p>During staging tests, one of our stakeholder teams reported a consistent error rate of less than 5% on specific requests. The errors were limited to a single route protected by a particular OPA policy and, intriguingly, only in one specific pod.</p><p>The same OPA policy worked perfectly fine in all other pods, and no other OPA policies showed any issues. Even more puzzling: there were no explicit error logs despite thorough error logging, except for a log indicating that the affected OPA instance became healthy for a fraction of a second, and then immediately unhealthy again and never recovers.</p><h2 id=4-reproducing>4. Reproducing<a hidden class=anchor aria-hidden=true href=#4-reproducing>#</a></h2><p>We went through the relevant code again and again, critically assessing what could have gone wrong, reviewed the end to end scenarios tests to see if there was anything we could cover more which didn&rsquo;t give any clue. Once these basic verifications are done, we could rule out few things.</p><ul><li>It can&rsquo;t be anything related to OPA policy issues - because the policy works in every other pod</li><li>OPA bundle downloading issues - Logging helped ruling this out. If a download issue or a malformed bundle was present, it does log an error</li></ul><p>Beyond this, only path we saw was reproducing the issue so we can have a closer look. I also tried different analyse paths with AI coding assistants(Claude Sonnet 4.5 and GPT 5), providing both Skipper and relevant OPA code, which didn&rsquo;t lead to anything solid, but lot of vague possibilities.</p><h3 id=replicate-everything-as-close-as-possible-to-the-issue-occurred-environment>Replicate everything as close as possible to the issue occurred environment<a hidden class=anchor aria-hidden=true href=#replicate-everything-as-close-as-possible-to-the-issue-occurred-environment>#</a></h3><ol><li>I used the same OPA bundles as our stakeholders and created a local setup. Made the configurations exact by splitting the data and policy bundles and including the discovery bundles in the configurations.</li><li>Configured status and decision log reporting to a local server where I can control them to simulate being slow, totally unavailable and recovering. Tried out variety of timing scenarios involving these and bundle server availabilities and slowness.</li></ol><h3 id=tools-to-analyse-logs>Tools to analyse logs<a hidden class=anchor aria-hidden=true href=#tools-to-analyse-logs>#</a></h3><p>Knowing whether the issue was reproduced or not was also a challenge. This is where AI could effectively help by providing the commands to isolate log patterns. In the issue occurred setup, there were close to 32 OPA instances getting created in parallel.</p><p>Meanwhile the stakeholder agreed to try it once more to gather anything that would help reproducing. This uncovered few more details. Even-though it didn&rsquo;t get reproduced in my local setup it was reproducing again in the stakeholder&rsquo;s setup, now failing for two OPA instances in one particular pod.</p><p>This confirmed two things,</p><ul><li>Failure is not specific to a particular OPA policy, but possibly can happen for any</li><li>Something specific to this stakeholder&rsquo;s setup is making it quite easy for the issue to happen</li></ul><p>With this newly revealed information, I kept on increasing the number of bundles in my local setup. I was going beyond what our stakeholder&rsquo;s had and as I go beyond 50 OPA instances, the mysterious issue start to happen consistently. I had the nice command I got from Co-pilot, confirmed it will isolate me the OPA instances that faced the failure and started analyzing the logs.</p><h2 id=5-debugging>5. Debugging<a hidden class=anchor aria-hidden=true href=#5-debugging>#</a></h2><p>This is where things got more interesting.</p><p>With increased logging, I could finally see more internal activity, but still no actual errors. Among the OPA plugins, I noticed that the bundle plugin was flipping from the OK state back to NOT_READY, which in turn triggered the brief healthy ‚Üí unhealthy transition in OPA&rsquo;s overall health status.</p><p>Since I never knew which exact OPA instance would show this behavior ahead of time, logging became my friend, traditional step debugging in the IDE wasn&rsquo;t practical. So I relied heavily on structured logs, they became my eyes inside the concurrency maze.</p><p>The mystery deepened further:</p><blockquote><p>there was no code path that actually transitioned the bundle plugin from OK to NOT_READY between those health flips.</p></blockquote><p>That raised a fundamental question:</p><p><strong>How could our health listener observe the bundle plugin switching back to NOT_READY when no execution ever performed that state change?</strong></p><h3 id=the-breakthrough>The Breakthrough<a hidden class=anchor aria-hidden=true href=#the-breakthrough>#</a></h3><figure class=align-center><img loading=lazy src=/images/beyond-race-detectors/race.webp#center alt="Two Go routines racing with each other, one with stale data" width=400><figcaption><p>Two Go routines racing with each other, one with stale data</p></figcaption></figure><p>I added one critical log line:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span> <span style=color:#66d9ef>for</span> <span style=color:#a6e22e>_</span>, <span style=color:#a6e22e>l</span> <span style=color:#f92672>:=</span> <span style=color:#66d9ef>range</span> <span style=color:#a6e22e>toNotify</span> {
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>m</span>.<span style=color:#a6e22e>logger</span>.<span style=color:#a6e22e>Info</span>(<span style=color:#e6db74>&#34;UpdatePluginStatus: plugin status listener %+v  status manager %+v&#34;</span>, <span style=color:#a6e22e>statuses</span>, <span style=color:#a6e22e>m</span>.<span style=color:#a6e22e>pluginStatus</span>)
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>l</span>(<span style=color:#a6e22e>statuses</span>)
</span></span><span style=display:flex><span> }
</span></span></code></pre></div><p>Which printed,</p><pre tabindex=0><code>&#34;UpdatePluginStatus: plugin status listener map[bundle:{**NOT_READY** \&#34;\&#34;} decision_logs:{OK \&#34;\&#34;} discovery:{OK \&#34;\&#34;} envoy_ext_authz_grpc:{OK \&#34;\&#34;} status:{OK \&#34;\&#34;}]  
status manager map[bundle:{**OK** \&#34;\&#34;} decision_logs:{OK \&#34;\&#34;} discovery:{OK \&#34;\&#34;} envoy_ext_authz_grpc:{OK \&#34;\&#34;} status:{OK \&#34;\&#34;}]&#34; bundle-name=bundles/discovery6.tar.gz
</code></pre><p><strong>The race:</strong></p><h3 id=the-timeline-two-routines-one-stale-snapshot>The Timeline: Two Routines, One Stale Snapshot<a hidden class=anchor aria-hidden=true href=#the-timeline-two-routines-one-stale-snapshot>#</a></h3><table><thead><tr><th>Time</th><th>Routine A</th><th>Routine B</th></tr></thead><tbody><tr><td><strong>T1</strong></td><td><code>UpdatePluginStatus("bundle", NOT_READY)</code></td><td></td></tr><tr><td><strong>T2</strong></td><td>Lock ‚Üí Update ‚Üí Create snapshot<strong>S1 = {NOT_READY}</strong> ‚Üí Unlock</td><td></td></tr><tr><td><strong>T3</strong></td><td>‚ö†Ô∏è Preempted before calling listeners</td><td></td></tr><tr><td><strong>T4</strong></td><td></td><td><code>UpdatePluginStatus("bundle", OK)</code></td></tr><tr><td><strong>T5</strong></td><td></td><td>Lock ‚Üí Update ‚Üí Create snapshot<strong>S2 = {OK}</strong> ‚Üí Unlock</td></tr><tr><td><strong>T6</strong></td><td></td><td>Call listeners with snapshot <strong>S2</strong> ‚úÖ</td></tr><tr><td><strong>T7</strong></td><td>Resumes ‚Äî Calls listeners with old snapshot <strong>S1</strong> ‚ùå</td><td></td></tr></tbody></table><p><strong>Result:</strong></p><p>Routine A&rsquo;s delayed listener call overwrote Routine B&rsquo;s newer state, making the system <em>appear</em> to revert to <code>NOT_READY</code> ‚Äî even though it was already healthy.</p><p><em>Timeline with routines getting pre-empted</em></p><h2 id=6-fixing>6. Fixing<a hidden class=anchor aria-hidden=true href=#6-fixing>#</a></h2><p>Once isolated we had a one-line fix that could be done in Skipper side. Instead of trusting the snapshot passed to the listener, directly query the manager&rsquo;s current state.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#a6e22e>manager</span>.<span style=color:#a6e22e>RegisterPluginStatusListener</span>(<span style=color:#e6db74>&#34;instance-health-check&#34;</span>, <span style=color:#66d9ef>func</span>(<span style=color:#a6e22e>_</span> <span style=color:#66d9ef>map</span>[<span style=color:#66d9ef>string</span>]<span style=color:#f92672>*</span><span style=color:#a6e22e>plugins</span>.<span style=color:#a6e22e>Status</span>) {
</span></span><span style=display:flex><span>  <span style=color:#75715e>// Get fresh status to workaround OPA issue https://github.com/open-policy-agent/opa/issues/8009</span>
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>status</span> <span style=color:#f92672>:=</span> <span style=color:#a6e22e>opa</span>.<span style=color:#a6e22e>manager</span>.<span style=color:#a6e22e>PluginStatus</span>() <span style=color:#75715e>// &lt;- fix, overrrides the pass in status map to the listener</span>
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>opa</span>.<span style=color:#a6e22e>healthy</span>.<span style=color:#a6e22e>Store</span>(<span style=color:#a6e22e>allPluginsReady</span>(<span style=color:#a6e22e>status</span>, <span style=color:#a6e22e>bundle</span>.<span style=color:#a6e22e>Name</span>, <span style=color:#a6e22e>discovery</span>.<span style=color:#a6e22e>Name</span>))
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>opa</span>.<span style=color:#a6e22e>Logger</span>().<span style=color:#a6e22e>Info</span>(<span style=color:#e6db74>&#34;OPA instance health updated: healthy=%t status=%+v&#34;</span>, <span style=color:#a6e22e>opa</span>.<span style=color:#a6e22e>healthy</span>.<span style=color:#a6e22e>Load</span>(), <span style=color:#a6e22e>status</span>)
</span></span><span style=display:flex><span> })
</span></span></code></pre></div><p><strong>Why this works:</strong> We bypass the snapshot race by always reading the real-time state from the source of truth (the manager), rather than relying on potentially stale snapshots delivered via notifications.</p><h2 id=7-learnings>7. Learnings<a hidden class=anchor aria-hidden=true href=#7-learnings>#</a></h2><h3 id=1-ai-as-a-productivity-tool-not-a-debugger>1. AI as a Productivity Tool, Not a Debugger<a hidden class=anchor aria-hidden=true href=#1-ai-as-a-productivity-tool-not-a-debugger>#</a></h3><p>AI models aren&rsquo;t mature enough yet to analyze complex multi-threading issues, but they excel at accelerating the process by generating log parsing commands, documenting findings, and explaining unfamiliar codebases. The actual debugging still requires human intuition.</p><h3 id=2-strategic-logging-over-verbose-logging>2. Strategic Logging Over Verbose Logging<a hidden class=anchor aria-hidden=true href=#2-strategic-logging-over-verbose-logging>#</a></h3><p>Good logging saves time, but there&rsquo;s a balance. Log state transitions with context, not every operation. Key questions will be, &ldquo;Will this log help confirm or rule out something critical? How often will it fire?&rdquo; Debug logging everywhere reduces readability and buries the signal in noise.</p><h3 id=3-every-bug-is-reproducible-with-enough-persistence>3. Every Bug is Reproducible (With Enough Persistence)<a hidden class=anchor aria-hidden=true href=#3-every-bug-is-reproducible-with-enough-persistence>#</a></h3><p>This seemed impossible to reproduce initially. By systematically varying parameters, replicating the environment, and investing consistent effort over days, I could find conditions to reliably reproduce it. Reproducibility isn&rsquo;t binary, it&rsquo;s about finding the right conditions. When stakes are high, persistence pays off.</p><h3 id=4-race-detectors-catch-data-races>4. Race Detectors Catch Data Races<a hidden class=anchor aria-hidden=true href=#4-race-detectors-catch-data-races>#</a></h3><p>Go&rsquo;s race detector excels at finding unsynchronized memory access but didn&rsquo;t detect event ordering races like this, logical races in state machines, or snapshot consistency problems. Multi-threading issues are often about event ordering and state consistency, not just data races. Manual reasoning is essential.</p><h3 id=5-logs-beat-debuggers-for-concurrent-bugs>5. Logs Beat Debuggers for Concurrent Bugs<a hidden class=anchor aria-hidden=true href=#5-logs-beat-debuggers-for-concurrent-bugs>#</a></h3><p>When issues reproduce randomly and concurrency is suspected, logging is more effective than IDE debugging. You can&rsquo;t step through race conditions. To compensate for losing interactive stack traces, print stack traces directly in logs at critical state transitions for debugging purposes.</p><h3 id=6-question-your-assumptions-explicitly>6. Question Your Assumptions Explicitly<a hidden class=anchor aria-hidden=true href=#6-question-your-assumptions-explicitly>#</a></h3><p>Write down what you believe to be true and verify each assumption:</p><ul><li>&ldquo;NOT_READY&rdquo; means broken" ‚Üí Actually: Real state was OK, snapshot was stale</li><li>&ldquo;All state changes notify&rdquo; ‚Üí Actually: Some state changes are protected by <code>sync.Once</code> so not all updates are notified</li></ul><p>Half the battle is realizing what you thought to be true isn&rsquo;t.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>This bug broadened my horizons, that multi-threading issues aren&rsquo;t always about locks and data races, they are about information propagation and timing assumptions as well.</p><h3 id=full-technical-details>Full technical details<a hidden class=anchor aria-hidden=true href=#full-technical-details>#</a></h3><ul><li><a href=https://github.com/zalando/skipper/issues/3687>Skipper Issue #3687</a></li><li><a href=https://github.com/zalando/skipper/pull/3692>Skipper PR #3692 Workaround</a></li><li><a href=https://github.com/zalando/skipper/pull/3562>Skipper PR #3562</a> (Preloading feature that exposed the bug)</li><li><a href=https://opensource.zalando.com/skipper/>OPA Integration in Skipper</a></li><li><a href=https://github.com/open-policy-agent/opa/issues/8009>OPA issue report #8009</a></li></ul><p>Cheers! üéØ ‚ú®</p><hr></div><footer class=post-footer><ul class=post-tags><li><a href=https://pushpalanka.com/tags/go/>Go</a></li><li><a href=https://pushpalanka.com/tags/concurrency/>Concurrency</a></li><li><a href=https://pushpalanka.com/tags/debugging/>Debugging</a></li><li><a href=https://pushpalanka.com/tags/multi-threading/>Multi-Threading</a></li><li><a href=https://pushpalanka.com/tags/opa/>Opa</a></li><li><a href=https://pushpalanka.com/tags/skipper/>Skipper</a></li><li><a href=https://pushpalanka.com/tags/zalando/>Zalando</a></li></ul><nav class=paginav><a class=prev href=https://pushpalanka.com/posts/stale-snapshot-case/><span class=title>¬´ Prev</span><br><span>The Case of the Stale Snapshot: Tracking a Logical Race in Real-World Systems</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Beyond Race Detectors: First-hand Experience Debugging a Multi-threaded Stale Data Issue on x" href="https://x.com/intent/tweet/?text=Beyond%20Race%20Detectors%3a%20First-hand%20Experience%20Debugging%20a%20Multi-threaded%20Stale%20Data%20Issue&amp;url=https%3a%2f%2fpushpalanka.com%2fposts%2fbeyond-race-detectors%2f&amp;hashtags=go%2cconcurrency%2cdebugging%2cmulti-threading%2copa%2cskipper%2czalando"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Beyond Race Detectors: First-hand Experience Debugging a Multi-threaded Stale Data Issue on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fpushpalanka.com%2fposts%2fbeyond-race-detectors%2f&amp;title=Beyond%20Race%20Detectors%3a%20First-hand%20Experience%20Debugging%20a%20Multi-threaded%20Stale%20Data%20Issue&amp;summary=Beyond%20Race%20Detectors%3a%20First-hand%20Experience%20Debugging%20a%20Multi-threaded%20Stale%20Data%20Issue&amp;source=https%3a%2f%2fpushpalanka.com%2fposts%2fbeyond-race-detectors%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Beyond Race Detectors: First-hand Experience Debugging a Multi-threaded Stale Data Issue on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fpushpalanka.com%2fposts%2fbeyond-race-detectors%2f&title=Beyond%20Race%20Detectors%3a%20First-hand%20Experience%20Debugging%20a%20Multi-threaded%20Stale%20Data%20Issue"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Beyond Race Detectors: First-hand Experience Debugging a Multi-threaded Stale Data Issue on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fpushpalanka.com%2fposts%2fbeyond-race-detectors%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Beyond Race Detectors: First-hand Experience Debugging a Multi-threaded Stale Data Issue on whatsapp" href="https://api.whatsapp.com/send?text=Beyond%20Race%20Detectors%3a%20First-hand%20Experience%20Debugging%20a%20Multi-threaded%20Stale%20Data%20Issue%20-%20https%3a%2f%2fpushpalanka.com%2fposts%2fbeyond-race-detectors%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Beyond Race Detectors: First-hand Experience Debugging a Multi-threaded Stale Data Issue on telegram" href="https://telegram.me/share/url?text=Beyond%20Race%20Detectors%3a%20First-hand%20Experience%20Debugging%20a%20Multi-threaded%20Stale%20Data%20Issue&amp;url=https%3a%2f%2fpushpalanka.com%2fposts%2fbeyond-race-detectors%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Beyond Race Detectors: First-hand Experience Debugging a Multi-threaded Stale Data Issue on ycombinator" href="https://news.ycombinator.com/submitlink?t=Beyond%20Race%20Detectors%3a%20First-hand%20Experience%20Debugging%20a%20Multi-threaded%20Stale%20Data%20Issue&u=https%3a%2f%2fpushpalanka.com%2fposts%2fbeyond-race-detectors%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://pushpalanka.com/>Pushpalanka</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>